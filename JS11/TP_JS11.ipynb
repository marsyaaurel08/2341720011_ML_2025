{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TUGAS PRAKTIKUM"
      ],
      "metadata": {
        "id": "1svEJcec_azf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Buatlah model SVM dengan menggunakan data voice.csv dengan ketentuan,**\n",
        "\n",
        "**Split data dengan rasio 70:30 dan 80:20 untuk setiap model yang akan dibangun.**\n",
        "\n",
        "**Gunakan model dengan kernel linier.**\n",
        "\n",
        "**Gunakan model dengan kernel polynomial.**\n",
        "\n",
        "**Gunakan model dengan kernel RBF.**\n",
        "\n",
        "**Tabulasikan performansi setiap split dan kernel berdasarkan metrik akurasi.**"
      ],
      "metadata": {
        "id": "FgtnVWffAPhE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Library**"
      ],
      "metadata": {
        "id": "-tofhZgcU3KD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tabulate import tabulate"
      ],
      "metadata": {
        "id": "EtBH1s-HU6hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Muat Dataset**\n"
      ],
      "metadata": {
        "id": "5oMcdIouVA9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Machine Learning   15/Data/voice.csv')"
      ],
      "metadata": {
        "id": "Q90akIQZVHdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pra-pemrosesan Data**"
      ],
      "metadata": {
        "id": "6Z9FqmylUbKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding Kolom Target ('label')\n",
        "# Ubah 'male' menjadi 1 dan 'female' menjadi 0\n",
        "df['label'] = df['label'].map({'male': 1, 'female': 0})\n",
        "\n",
        "# Pemisahan Fitur (X) dan Target (y)\n",
        "X = df.drop('label', axis=1)\n",
        "y = df['label']\n",
        "\n",
        "# Scaling Fitur\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"\\nShape data (X, y):\", X_scaled.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1NgKo5MUeDp",
        "outputId": "de116c1b-6269-4b54-84dd-46a3be2e6867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape data (X, y): (3168, 20) (3168,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Membuat Fungsi yang menerima data, rasio, split, dan jenis kernel, kemudian megembalikan nilai akurasi**"
      ],
      "metadata": {
        "id": "wOhgLUxvVUOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_svm(X, y, test_size_ratio, kernel_type):\n",
        "    \"\"\"\n",
        "    Melatih model SVM dengan kernel tertentu dan rasio split,\n",
        "    kemudian mengembalikan akurasi pada data uji (test).\n",
        "    \"\"\"\n",
        "    # Menghitung test_size dari rasio (misalnya 0.3 untuk 70:30)\n",
        "    test_size = test_size_ratio / 100.0\n",
        "\n",
        "    # Split Data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Inisialisasi dan Latih Model SVM\n",
        "    if kernel_type == 'linear':\n",
        "        model = SVC(kernel='linear', random_state=42)\n",
        "    elif kernel_type == 'poly':\n",
        "        # Untuk polynomial, biasanya menggunakan degree=3\n",
        "        model = SVC(kernel='poly', degree=3, random_state=42)\n",
        "    elif kernel_type == 'rbf':\n",
        "        # RBF (Radial Basis Function) adalah kernel default\n",
        "        model = SVC(kernel='rbf', random_state=42)\n",
        "    else:\n",
        "        raise ValueError(\"Kernel tidak valid.\")\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Prediksi dan Evaluasi\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "Ayr-7fxYVcio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eksperimen dan pengumpulan hasil**"
      ],
      "metadata": {
        "id": "dTR65jQZVgg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Daftar konfigurasi yang akan diuji\n",
        "configurations = [\n",
        "    {'split_ratio': '70:30', 'test_size': 30, 'kernel': 'linear'},\n",
        "    {'split_ratio': '70:30', 'test_size': 30, 'kernel': 'poly'},\n",
        "    {'split_ratio': '70:30', 'test_size': 30, 'kernel': 'rbf'},\n",
        "    {'split_ratio': '80:20', 'test_size': 20, 'kernel': 'linear'},\n",
        "    {'split_ratio': '80:20', 'test_size': 20, 'kernel': 'poly'},\n",
        "    {'split_ratio': '80:20', 'test_size': 20, 'kernel': 'rbf'},\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "print(\"\\nMemulai Pelatihan dan Evaluasi Model...\")\n",
        "for config in configurations:\n",
        "    ratio = config['split_ratio']\n",
        "    size = config['test_size']\n",
        "    kernel = config['kernel']\n",
        "\n",
        "    # Pelatihan dan Evaluasi\n",
        "    accuracy = train_and_evaluate_svm(X_scaled, y, size, kernel)\n",
        "\n",
        "    # Simpan Hasil\n",
        "    results.append([ratio, kernel, f\"{accuracy:.4f}\"])\n",
        "    print(f\"-> Selesai: Split {ratio}, Kernel {kernel}, Akurasi: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob240Ls2VlcP",
        "outputId": "3ac13c53-3f7d-46c8-bf7a-521bb51b835b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Memulai Pelatihan dan Evaluasi Model...\n",
            "-> Selesai: Split 70:30, Kernel linear, Akurasi: 0.9790\n",
            "-> Selesai: Split 70:30, Kernel poly, Akurasi: 0.9590\n",
            "-> Selesai: Split 70:30, Kernel rbf, Akurasi: 0.9832\n",
            "-> Selesai: Split 80:20, Kernel linear, Akurasi: 0.9748\n",
            "-> Selesai: Split 80:20, Kernel poly, Akurasi: 0.9574\n",
            "-> Selesai: Split 80:20, Kernel rbf, Akurasi: 0.9826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tabulasi Performansi**"
      ],
      "metadata": {
        "id": "mu1IkCGoVo79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Header untuk Tabel\n",
        "headers = [\"Split Data\", \"Kernel SVM\", \"Akurasi (Test Set)\"]\n",
        "\n",
        "# Cetak Tabel menggunakan tabulate\n",
        "print(\"HASIL PERBANDINGAN PERFORMASI MODEL SVM\")\n",
        "print(tabulate(results, headers=headers, tablefmt=\"fancy_grid\"))\n",
        "\n",
        "# Contoh interpretasi\n",
        "best_model = max(results, key=lambda item: float(item[2]))\n",
        "print(f\"\\nModel Terbaik berdasarkan Akurasi: Split {best_model[0]} dengan Kernel {best_model[1]} (Akurasi: {best_model[2]})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XX30DOGVsNK",
        "outputId": "f772da79-37fe-4706-dd79-81b98da79393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HASIL PERBANDINGAN PERFORMASI MODEL SVM\n",
            "╒══════════════╤══════════════╤══════════════════════╕\n",
            "│ Split Data   │ Kernel SVM   │   Akurasi (Test Set) │\n",
            "╞══════════════╪══════════════╪══════════════════════╡\n",
            "│ 70:30        │ linear       │               0.979  │\n",
            "├──────────────┼──────────────┼──────────────────────┤\n",
            "│ 70:30        │ poly         │               0.959  │\n",
            "├──────────────┼──────────────┼──────────────────────┤\n",
            "│ 70:30        │ rbf          │               0.9832 │\n",
            "├──────────────┼──────────────┼──────────────────────┤\n",
            "│ 80:20        │ linear       │               0.9748 │\n",
            "├──────────────┼──────────────┼──────────────────────┤\n",
            "│ 80:20        │ poly         │               0.9574 │\n",
            "├──────────────┼──────────────┼──────────────────────┤\n",
            "│ 80:20        │ rbf          │               0.9826 │\n",
            "╘══════════════╧══════════════╧══════════════════════╛\n",
            "\n",
            "Model Terbaik berdasarkan Akurasi: Split 70:30 dengan Kernel rbf (Akurasi: 0.9832)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Gunakan data pada praktikum 5 untuk membuat model klasifikasi siang dan malam menggunakan SVM dengan kernel RBF menggunakan fitur histrogram. Gunakan rasio 80:20. Anda dapat bereksperimen dengan hyperparameter tunning dari kernel RBF. Catat performansi akurasinya!**"
      ],
      "metadata": {
        "id": "J8nd4OFkWJUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Image directories\n",
        "train_dir = \"images/training/\"\n",
        "test_dir = \"images/test/\""
      ],
      "metadata": {
        "id": "gHAQTDdjWTSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "462ac027",
        "outputId": "3d794f29-8567-4bd1-d03f-432475bc0877"
      },
      "source": [
        "train_img = load_dataset(train_dir)\n",
        "train_std_img_list = preprocess(train_img)\n",
        "\n",
        "test_img = load_dataset(test_dir)\n",
        "test_std_img_list = preprocess(test_img)\n",
        "\n",
        "print(f\"Number of preprocessed training images: {len(train_std_img_list)}\")\n",
        "print(f\"Number of preprocessed test images: {len(test_std_img_list)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of preprocessed training images: 240\n",
            "Number of preprocessed test images: 160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1a1f4b6"
      },
      "source": [
        "**Extract Histogram Features**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eb428fe",
        "outputId": "f88259cf-6ad0-44cf-fea5-644910623a4f"
      },
      "source": [
        "def extract_histogram_features(image):\n",
        "    # Convert image to HSV color space\n",
        "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "    # Define histogram parameters\n",
        "    # H: 0-180, S: 0-255, V: 0-255\n",
        "    hist_bins = 32\n",
        "    hist_range_h = [0, 180]\n",
        "    hist_range_sv = [0, 256]\n",
        "\n",
        "    # Compute histogram for Hue channel\n",
        "    hist_h = cv2.calcHist([hsv_image], [0], None, [hist_bins], hist_range_h)\n",
        "    # Compute histogram for Saturation channel\n",
        "    hist_s = cv2.calcHist([hsv_image], [1], None, [hist_bins], hist_range_sv)\n",
        "    # Compute histogram for Value channel\n",
        "    hist_v = cv2.calcHist([hsv_image], [2], None, [hist_bins], hist_range_sv)\n",
        "\n",
        "    # Normalize histograms\n",
        "    cv2.normalize(hist_h, hist_h, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
        "    cv2.normalize(hist_s, hist_s, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
        "    cv2.normalize(hist_v, hist_v, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
        "\n",
        "    # Concatenate normalized histograms into a single feature vector\n",
        "    feature_vector = np.concatenate((hist_h.flatten(), hist_s.flatten(), hist_v.flatten()))\n",
        "\n",
        "    return feature_vector\n",
        "\n",
        "# Apply the function to training data\n",
        "train_features = []\n",
        "train_labels = []\n",
        "for img, label in train_std_img_list:\n",
        "    features = extract_histogram_features(img)\n",
        "    train_features.append(features)\n",
        "    train_labels.append(label)\n",
        "\n",
        "train_features = np.array(train_features)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "# Apply the function to test data\n",
        "test_features = []\n",
        "test_labels = []\n",
        "for img, label in test_std_img_list:\n",
        "    features = extract_histogram_features(img)\n",
        "    test_features.append(features)\n",
        "    test_labels.append(label)\n",
        "\n",
        "test_features = np.array(test_features)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "print(f\"Shape of training features: {train_features.shape}\")\n",
        "print(f\"Shape of training labels: {train_labels.shape}\")\n",
        "print(f\"Shape of test features: {test_features.shape}\")\n",
        "print(f\"Shape of test labels: {test_labels.shape}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training features: (240, 96)\n",
            "Shape of training labels: (240,)\n",
            "Shape of test features: (160, 96)\n",
            "Shape of test labels: (160,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dccfe3bd"
      },
      "source": [
        "**Train model SVM dengan RBF kernel menggunakan rasio 80:20**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47dc2b0f",
        "outputId": "c6e8c2b7-359c-46c9-f4ee-0275fc9c6c0a"
      },
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split training data into 80:20 for internal validation during GridSearchCV\n",
        "# (GridSearchCV will handle the splits internally, but we use X_train_tuned/y_train_tuned for fitting the GridSearchCV object)\n",
        "# For the overall split, we already have train_features and test_features based on the original 80:20 ratio from the problem statement\n",
        "# So, the problem implies using the preprocessed train_features as the training set for the model, and test_features as the test set.\n",
        "\n",
        "X_train_svm, X_val_svm, y_train_svm, y_val_svm = train_test_split(train_features, train_labels, test_size=0.2, random_state=42, stratify=train_labels)\n",
        "\n",
        "# Define the parameter grid for RBF kernel\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100, 1000],\n",
        "    'gamma': [0.0001, 0.001, 0.01, 0.1, 1]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV with SVC (RBF kernel is default)\n",
        "grid_search = GridSearchCV(SVC(kernel='rbf', random_state=42), param_grid, cv=5, verbose=2, n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV on the training features (from the 80:20 split of original data)\n",
        "print(\"Fitting GridSearchCV to find best hyperparameters...\")\n",
        "grid_search.fit(X_train_svm, y_train_svm)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Get the best model\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the original test set\n",
        "y_pred_test = best_svm_model.predict(test_features)\n",
        "accuracy_test = accuracy_score(test_labels, y_pred_test)\n",
        "\n",
        "print(f\"Accuracy on the test set with best RBF SVM model: {accuracy_test:.4f}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting GridSearchCV to find best hyperparameters...\n",
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "Best parameters: {'C': 1, 'gamma': 0.1}\n",
            "Best cross-validation score: 0.9947\n",
            "Accuracy on the test set with best RBF SVM model: 1.0000\n"
          ]
        }
      ]
    }
  ]
}